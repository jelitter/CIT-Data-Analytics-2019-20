{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Shape: (45211, 19)\n"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# url = \"https://github.com/jelitter/CIT-Data-Analytics-2019-20/blob/master/Project-2/bank.csv\"\n",
    "\n",
    "dataset = read_csv(r'C:\\\\Users\\\\yojak\\\\Documents\\\\Data-Analytics-Git\\\\Project-2\\\\bank.csv')\n",
    "\n",
    "\n",
    "# Pre-processing dataset\n",
    "le_en = preprocessing.LabelEncoder()\n",
    "for col in ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'y']:\n",
    "    dataset[col] = dataset[col].astype('category')\n",
    "    dataset[col] = le_en.fit_transform(dataset[col])\n",
    "# print(dataset.dtypes)\n",
    "# print(dataset.head())\n",
    "\n",
    "# dataset.head()\n",
    "\n",
    "print(f\"Shape: {dataset.shape}\")\n",
    "\n",
    "# scatter_matrix(dataset.corr(), figsize=(15,15))\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Create two data-sets as follows:\n",
    "\n",
    "  * (a) **Dataset 1**: age,job,poutcome, balance, default and y, where y is the class attribute.\n",
    "\n",
    "  * (b) **Dataset 2**: age,job,poutcome, balance, default and loan, where loan is the class attribute.\n",
    "\n",
    "### Apply a classification algorithm on each dataset and report the error. Which dataset has a higher accuracy (lower error)? Note, all the data should be used for training the model from both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nDataset 1:\nLR: Accuracy: 0.882924 - Error: 0.117076 (Std Dev: 0.000173)\n\nDataset 2:\nLR: Accuracy: 0.839792 - Error: 0.160208 (Std Dev: 0.000142)\n"
    },
    {
     "data": {
      "text/plain": "' \\nOUTPUT:\\n\\n    Dataset 1:LR: Accuracy: 0.882924 - Error: 0.117076 (Std Dev: 0.000173)\\n\\n    Dataset 2:\\n    LR: Accuracy: 0.839792 - Error: 0.160208 (Std Dev: 0.000142)\\n\\nDataset 1 has higher accuracy (lower error).\\n'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_accuracy(ds):\n",
    "    array = ds.values\n",
    "    # 6th column (index 5) is 'y' for Dataset 1, 'loan' for Dataset 2\n",
    "    X = array[:,0:5]\n",
    "    Y = array[:,5]\n",
    "    X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=1, random_state=1)\n",
    "\n",
    "    # Tested all these algorithms. LogisticRegression (LR) resulted in the highest accuracy.\n",
    "    #   LR: Accuracy: 0.882714 - Error: 0.117286 (Std Dev: 0.000201)\n",
    "    #   LDA: Accuracy: 0.882438 - Error: 0.117562 (Std Dev: 0.000389)\n",
    "    #   KNN: Accuracy: 0.869857 - Error: 0.130143 (Std Dev: 0.002554)\n",
    "    #   CART: Accuracy: 0.818735 - Error: 0.181265 (Std Dev: 0.007136)\n",
    "    #   NB: Accuracy: 0.870327 - Error: 0.129673 (Std Dev: 0.001553)\n",
    "\n",
    "    model = ('LR', LogisticRegression(solver='liblinear', multi_class='ovr'))\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    cv_results = cross_val_score(model[1], X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    print('%s: Accuracy: %f - Error: %f (Std Dev: %f)' % (model[0], cv_results.mean(), (1 - cv_results.mean()), cv_results.std()))\n",
    "\n",
    "\n",
    "# Dataset 1\n",
    "dataset_1 = dataset[['age','job','poutcome','balance','default', 'y']]\n",
    "print(\"\\nDataset 1:\")\n",
    "test_accuracy(dataset_1)\n",
    "\n",
    "# Dataset 2\n",
    "dataset_2 = dataset[['age','job','poutcome','balance','default', 'loan']]\n",
    "print(\"\\nDataset 2:\")\n",
    "test_accuracy(dataset_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "OUTPUT:\n",
    "\n",
    "    Dataset 1:LR: Accuracy: 0.882924 - Error: 0.117076 (Std Dev: 0.000173)\n",
    "\n",
    "    Dataset 2:\n",
    "    LR: Accuracy: 0.839792 - Error: 0.160208 (Std Dev: 0.000142)\n",
    "\n",
    "Dataset 1 has higher accuracy (lower error).\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  }
 ]
}